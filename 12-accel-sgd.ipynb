{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerated SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)\n",
    "\n",
    "bs = 1024\n",
    "xmean,xstd = 0.28, 0.35\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[xl] = [(TF.to_tensor(o)-xmean)/xstd for o in b[xl]]\n",
    "\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "astats = ActivationStats(fc.risinstance(GeneralRelu))\n",
    "cbs = [DeviceCB(), metrics, ProgressCB(plot=True), astats]\n",
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "lrf_cbs = [DeviceCB(), LRFinderCB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, params, lr, wd=0.):\n",
    "        params = list(params)\n",
    "        fc.store_attr()\n",
    "        self.i = 0\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                self.reg_step(p)\n",
    "                self.opt_step(p)\n",
    "        self.i +=1\n",
    "\n",
    "    def opt_step(self, p): p -= p.grad * self.lr\n",
    "    def reg_step(self, p):\n",
    "        if self.wd != 0: p *= 1 - self.lr*self.wd\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Ideas of the `SGD` Class\n",
    "\n",
    "1. **Initialization (`__init__`):**\n",
    "   - **Parameters:** Takes a list of parameters (`params`), a learning rate (`lr`), and an optional weight decay (`wd`).\n",
    "   - **Setup:** Initializes the list of parameters and stores attributes for later use. A counter `i` is also initialized.\n",
    "\n",
    "2. **Optimization Step (`step`):**\n",
    "   - **No Gradient Tracking:** Executes the optimization without tracking gradients (`torch.no_grad()`).\n",
    "   - **Parameter Updates:** For each parameter, performs regularization and optimization steps. The counter `i` is incremented after each step.\n",
    "\n",
    "3. **Optimization Step (`opt_step`):**\n",
    "   - **Parameter Update:** Updates each parameter by subtracting the gradient scaled by the learning rate (`p -= p.grad * self.lr`).\n",
    "\n",
    "4. **Regularization Step (`reg_step`):**\n",
    "   - **Weight Decay:** If weight decay is applied, it adjusts the parameters by multiplying them by `(1 - lr * wd)`.\n",
    "\n",
    "5. **Zero Gradient (`zero_grad`):**\n",
    "   - **Gradient Reset:** Sets the gradients of all parameters to zero to prepare for the next optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=0.4, cbs=cbs, opt_func=SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the difference between *weight decay* and *L2 regularization*:\n",
    "\n",
    "``` python\n",
    "weight -= lr*wd*weight\n",
    "```\n",
    "\n",
    "...vs...\n",
    "\n",
    "``` python\n",
    "weight.grad += wd*weight\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.linspace(-4, 4, 100)\n",
    "ys = 1 - (xs/3) ** 2 + torch.randn(100) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(2,2, figsize=(12,8))\n",
    "betas = [0.5,0.7,0.9,0.99]\n",
    "for beta,ax in zip(betas, axs.flatten()):\n",
    "    ax.scatter(xs,ys)\n",
    "    avg,res = 0,[]\n",
    "    for yi in ys:\n",
    "        avg = beta*avg + (1-beta)*yi\n",
    "        res.append(avg)\n",
    "    ax.plot(xs,np.array(res), color='red');\n",
    "    ax.set_title(f'beta={beta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum(SGD):\n",
    "    def __init__(self, params, lr, wd=0., mom=0.9):\n",
    "        super().__init__(params, lr=lr, wd=wd)\n",
    "        self.mom=mom\n",
    "\n",
    "    def opt_step(self, p):\n",
    "        if not hasattr(p, 'grad_avg'): p.grad_avg = torch.zeros_like(p.grad)\n",
    "        p.grad_avg = p.grad_avg*self.mom + p.grad*(1-self.mom)\n",
    "        p -= self.lr * p.grad_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Initialization (`__init__`):**\n",
    "   - **Inherits from `SGD`:** Uses the base class `SGD` for its core functionality.\n",
    "   - **Momentum Parameter (`mom`):** Introduces a momentum term (`mom`), which is used to update the moving average of gradients.\n",
    "\n",
    "2. **Optimization Step (`opt_step`):**\n",
    "   - **Gradient Averaging:**\n",
    "     - **Initialization:** If a parameter does not already have a `grad_avg` attribute, it initializes it to zeros with the same shape as the gradient.\n",
    "     - **Update Averaging:** Updates the moving average of gradients using the momentum term (`grad_avg = grad_avg * mom + grad * (1 - mom)`).\n",
    "   - **Parameter Update:** Updates each parameter using the learning rate and the averaged gradient (`p -= self.lr * p.grad_avg`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=1.5, cbs=cbs, opt_func=Momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astats.color_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp(SGD):\n",
    "    def __init__(self, params, lr, wd=0., sqr_mom=0.99, eps=1e-5):\n",
    "        super().__init__(params, lr=lr, wd=wd)\n",
    "        self.sqr_mom,self.eps = sqr_mom,eps\n",
    "\n",
    "    def opt_step(self, p):\n",
    "        if not hasattr(p, 'sqr_avg'): p.sqr_avg = p.grad**2\n",
    "        p.sqr_avg = p.sqr_avg*self.sqr_mom + p.grad**2*(1-self.sqr_mom)\n",
    "        p -= self.lr * p.grad/(p.sqr_avg.sqrt() + self.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Ideas of the `RMSProp` Class\n",
    "\n",
    "1. **Initialization (`__init__`):**\n",
    "   - **Inherits from `SGD`:** It leverages the base functionality of `SGD`.\n",
    "   - **Additional Parameters:**\n",
    "     - **Squared Gradient Momentum (`sqr_mom`)**: This controls how much of the previous squared gradients contribute to the current step (similar to exponential moving average).\n",
    "     - **Epsilon (`eps`)**: A small constant added to avoid division by zero, ensuring numerical stability.\n",
    "\n",
    "2. **Optimization Step (`opt_step`):**\n",
    "   - **Squared Gradient Averaging:**\n",
    "     - **Initialization:** If a parameter doesn't have a `sqr_avg` attribute, it initializes it to the squared gradient:\n",
    "     $$ p.sqr\\_avg = p.grad^2 $$\n",
    "     - **Exponential Moving Average:** Updates the moving average of squared gradients, which gives more weight to recent gradient squares and less to past ones:  \n",
    "     $$ p.sqr\\_avg = p.sqr\\_avg \\times \\text{sqr\\_mom} + p.grad^2 \\times (1 - \\text{sqr\\_mom}) $$\n",
    "     \n",
    "   - **Adaptive Learning Rate:**\n",
    "     - The gradient is scaled down based on the square root of the moving average of squared gradients. This creates an adaptive learning rate, where large gradients are scaled down and small gradients are allowed to influence updates more:\n",
    "     $$ p \\mathrel{-=} \\frac{\\text{lr} \\times p.grad}{\\sqrt{p.sqr\\_avg} + \\epsilon} $$\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Why Use `sqr_avg`?**\n",
    "   - The averaging of squared gradients helps to stabilize the learning process. If a gradient is large, its squared value will dominate, slowing down the update for that parameter. If the gradient is small, the update proceeds with less dampening. This adaptive adjustment of learning rates helps prevent exploding or vanishing gradients in different dimensions.\n",
    "\n",
    "2. **The Role of `eps`:**\n",
    "   - The epsilon term prevents division by zero, especially when the squared gradient values are very small. Without it, division by zero or extremely large updates could destabilize training.\n",
    "\n",
    "3. **When is RMSProp Useful?**\n",
    "   - **Adaptive Learning Rates:** RMSProp is particularly effective when the scale of the gradients varies significantly across dimensions, making it ideal for deep networks where gradient magnitudes can fluctuate wildly.\n",
    "   - **Stabilization:** By adapting the learning rate based on the variance of past gradients, RMSProp can make training more robust and prevent overshooting, especially in non-convex loss surfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why would a dominating squared value slow down updates?\n",
    "\n",
    "1. **Larger Gradients = Larger Squared Values:**\n",
    "   - When the gradient for a particular parameter \\( p \\) is large, its squared value will be even larger. This causes \\( p.sqr\\_avg \\) to increase.\n",
    "   - **Example:**  \n",
    "     If \\( p.grad = 2 \\), then \\( p.grad^2 = 4 \\). This value adds more weight to the moving average \\( p.sqr\\_avg \\).\n",
    "\n",
    "2. **Impact on Learning Rate:**\n",
    "   - The update rule for RMSProp is:\n",
    "     $$ \n",
    "     p \\mathrel{-=} \\frac{\\text{lr} \\times p.grad}{\\sqrt{p.sqr\\_avg} + \\epsilon} \n",
    "     $$\n",
    "   - As \\( p.sqr\\_avg \\) grows larger, the denominator \\( \\sqrt{p.sqr\\_avg} \\) increases.\n",
    "   - A larger denominator reduces the size of the update step because the gradient \\( p.grad \\) is divided by a bigger number.\n",
    "\n",
    "3. **Slowing Down Updates:**\n",
    "   - When \\( p.sqr\\_avg \\) is large (due to large squared gradients), the effective learning rate for that parameter becomes smaller. This **slows down the updates** for that parameter.\n",
    "   - **Intuition:** If a gradient is consistently large, RMSProp interprets it as a sign that updates should be more cautious, preventing overshooting during optimization.\n",
    "\n",
    "### Why is this good?\n",
    "- **Adaptive Adjustment:** If a parameter experiences large fluctuations in its gradient, slowing down its update helps stabilize the training. Conversely, if a parameter has small gradients, RMSProp allows larger updates.\n",
    "- **Preventing Exploding Gradients:** When gradients are large, updates can become too aggressive and lead to exploding gradients. RMSProp curbs this by reducing the effective learning rate for large gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=3e-3, cbs=cbs, opt_func=RMSProp)\n",
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astats.color_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(SGD):\n",
    "    def __init__(self, params, lr, wd=0., beta1=0.9, beta2=0.99, eps=1e-5):\n",
    "        super().__init__(params, lr=lr, wd=wd)\n",
    "        self.beta1,self.beta2,self.eps = beta1,beta2,eps\n",
    "\n",
    "    def opt_step(self, p):\n",
    "        if not hasattr(p, 'avg'): p.avg = torch.zeros_like(p.grad.data)\n",
    "        if not hasattr(p, 'sqr_avg'): p.sqr_avg = torch.zeros_like(p.grad.data)\n",
    "        p.avg = self.beta1*p.avg + (1-self.beta1)*p.grad\n",
    "        unbias_avg = p.avg / (1 - (self.beta1**(self.i+1)))\n",
    "        p.sqr_avg = self.beta2*p.sqr_avg + (1-self.beta2)*(p.grad**2)\n",
    "        unbias_sqr_avg = p.sqr_avg / (1 - (self.beta2**(self.i+1)))\n",
    "        p -= self.lr * unbias_avg / (unbias_sqr_avg + self.eps).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer\n",
    "\n",
    "Adam combines the ideas from both **Momentum** and **RMSProp** to provide a more robust and adaptive optimization algorithm. The key components are:\n",
    "\n",
    "1. **Running Average of Gradients (Momentum-like Behavior):**\n",
    "   $$ \n",
    "   p.avg = \\beta_1 \\cdot p.avg + (1 - \\beta_1) \\cdot p.grad\n",
    "   $$\n",
    "   - This computes an exponentially weighted moving average of the gradients, similar to Momentum, where \\( \\beta_1 \\) controls the smoothness of this average.\n",
    "   - \\( p.avg \\) accumulates the momentum of the gradient over time.\n",
    "\n",
    "2. **Running Average of Squared Gradients (RMSProp-like Behavior):**\n",
    "   $$ \n",
    "   p.sqr\\_avg = \\beta_2 \\cdot p.sqr\\_avg + (1 - \\beta_2) \\cdot (p.grad^2)\n",
    "   $$\n",
    "   - This tracks the moving average of squared gradients, where \\( \\beta_2 \\) controls the smoothness of this moving average.\n",
    "   - This part mimics the behavior of RMSProp by adapting the learning rate based on recent squared gradients.\n",
    "\n",
    "3. **Bias-Correction:**\n",
    "   - To counteract the bias introduced by initializing \\( p.avg \\) and \\( p.sqr\\_avg \\) to zeros, we apply bias correction:\n",
    "     $$\n",
    "     \\text{unbias\\_avg} = \\frac{p.avg}{1 - \\beta_1^{t+1}}\n",
    "     $$\n",
    "     $$\n",
    "     \\text{unbias\\_sqr\\_avg} = \\frac{p.sqr\\_avg}{1 - \\beta_2^{t+1}}\n",
    "     $$\n",
    "\n",
    "   - This ensures that early iterations don't underestimate the gradient values.\n",
    "\n",
    "4. **Update Step:**\n",
    "   $$\n",
    "   p \\mathrel{-=} \\frac{\\text{lr} \\cdot \\text{unbias\\_avg}}{\\sqrt{\\text{unbias\\_sqr\\_avg}} + \\epsilon}\n",
    "   $$\n",
    "\n",
    "   - Adam combines the two running averages (of the gradient and squared gradient) to scale the update.\n",
    "   - The bias-corrected running average of the gradient is divided by the square root of the bias-corrected squared gradient, ensuring that the update is adaptive and stable.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Adaptive Learning Rates:** Adam adjusts the learning rate for each parameter based on the gradient magnitudes and momentum, making it effective for sparse gradients or noisy data.\n",
    "- **Bias Correction:** The bias correction ensures that early updates are accurate, even though the moving averages are initialized to zero.\n",
    "- **Stability:** By combining momentum with RMSProp's adaptive learning, Adam offers a stable and efficient way to optimize deep networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=6e-3, cbs=cbs, opt_func=Adam)\n",
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already seen how we can easily write a custom LR-adjusting callback or `Learner`, or can use the predefined PyTorch schedulers. We'll use the predefined ones for now since there's nothing new to learn in implementing them ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(o for o in dir(lr_scheduler) if o[0].isupper() and o[1].islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(filter(lambda x: x[0].isupper() and x[1].islower(), dir(lr_scheduler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TrainLearner(get_model(), dls, F.cross_entropy, lr=6e-3, cbs=[DeviceCB(), SingleBatchCB()])\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = learn.opt\n",
    "' '.join(o for o in dir(opt) if o[0]!='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = next(iter(learn.model.parameters()))\n",
    "st = opt.state[param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(opt.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = opt.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = lr_scheduler.CosineAnnealingLR(opt, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Annealing is a learning rate scheduler that reduces the learning rate following a cosine curve. This technique is designed to progressively lower the learning rate as training progresses, helping the model converge more effectively.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Cosine Function for Learning Rate:**\n",
    "   The learning rate is updated according to a cosine function over a predefined number of iterations or epochs:\n",
    "   $$\n",
    "   \\text{lr}(t) = \\frac{\\text{lr}_{\\text{min}}}{2} \\left( 1 + \\cos\\left( \\frac{t}{T} \\pi \\right) \\right)\n",
    "   $$\n",
    "   where:\n",
    "   - \\( t \\) is the current time step (iteration or epoch).\n",
    "   - \\( T \\) is the total number of time steps (iterations or epochs).\n",
    "   - \\( \\text{lr}_{\\text{min}} \\) is the minimum learning rate.\n",
    "\n",
    "2. **Smooth Decay:**\n",
    "   The learning rate starts at its maximum value, then decays smoothly following the shape of the cosine function. This smooth decay helps the model avoid overshooting during training and leads to better convergence.\n",
    "\n",
    "3. **Restarts (Optional):**\n",
    "   Sometimes, the cosine annealing schedule includes restarts, where the learning rate is periodically reset to a higher value (or even the maximum). This allows the model to escape local minima and explore other regions of the loss landscape before continuing the decay:\n",
    "   $$\n",
    "   T_{i+1} = \\frac{T_i}{2}\n",
    "   $$\n",
    "\n",
    "### Advantages:\n",
    "- **Gradual Learning Rate Reduction:** Cosine annealing offers a smooth and gradual decrease in the learning rate, which can help models converge better compared to abrupt drops.\n",
    "- **Helps Escape Local Minima:** The optional restarts can provide a form of exploration during training, allowing the model to avoid getting stuck in local minima.\n",
    "\n",
    "Cosine annealing is particularly useful in tasks where a smooth decay in the learning rate improves convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched.base_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_lrs(sched, steps):\n",
    "    lrs = [sched.get_last_lr()]\n",
    "    for i in range(steps):\n",
    "        sched.optimizer.step()\n",
    "        sched.step()\n",
    "        lrs.append(sched.get_last_lr())\n",
    "    plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_lrs(sched, 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class BaseSchedCB(Callback):\n",
    "    def __init__(self, sched): self.sched = sched\n",
    "    def before_fit(self, learn): self.schedo = self.sched(learn.opt)\n",
    "    def _step(self, learn):\n",
    "        if learn.training: self.schedo.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class BatchSchedCB(BaseSchedCB):\n",
    "    def after_batch(self, learn): self._step(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class HasLearnCB(Callback):\n",
    "    def before_fit(self, learn): self.learn = learn \n",
    "    def after_fit(self, learn): self.learn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RecorderCB(Callback):\n",
    "    def __init__(self, **d): self.d = d\n",
    "    def before_fit(self, learn):\n",
    "        self.recs = {k:[] for k in self.d}\n",
    "        self.pg = learn.opt.param_groups[0]\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        if not learn.training: return\n",
    "        for k,v in self.d.items():\n",
    "            self.recs[k].append(v(self))\n",
    "\n",
    "    def plot(self):\n",
    "        for k,v in self.recs.items():\n",
    "            plt.plot(v, label=k)\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lr(cb): return cb.pg['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = 3 * len(dls.train)\n",
    "sched = partial(lr_scheduler.CosineAnnealingLR, T_max=tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "rec = RecorderCB(lr=_lr)\n",
    "xtra = [BatchSchedCB(sched),rec]\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=2e-2, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpochSchedCB(BaseSchedCB):\n",
    "    def after_epoch(self, learn): self._step(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = partial(lr_scheduler.CosineAnnealingLR, T_max=3)\n",
    "set_seed(42)\n",
    "xtra = [EpochSchedCB(sched),rec]\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=2e-2, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1cycle training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paper](https://arxiv.org/abs/1803.09820) by Leslie Smith."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Cycle is a training strategy that adjusts the learning rate and momentum dynamically throughout the training process. It was popularized by Leslie Smith and is particularly effective for faster convergence and better generalization in deep learning models.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Learning Rate Schedule:**\n",
    "   The learning rate is increased in the first half of the training and then decreased in the second half, following a triangular shape:\n",
    "   $$\n",
    "   \\text{lr}(t) =\n",
    "   \\begin{cases}\n",
    "   \\text{lr}_{\\text{max}} - (\\text{lr}_{\\text{max}} - \\text{lr}_{\\text{min}}) \\cdot \\frac{t}{T/2} & \\text{if } t \\leq T/2 \\\\\n",
    "   \\text{lr}_{\\text{min}} + (\\text{lr}_{\\text{max}} - \\text{lr}_{\\text{min}}) \\cdot \\frac{t - T/2}{T/2} & \\text{if } t > T/2\n",
    "   \\end{cases}\n",
    "   $$\n",
    "   - \\( \\text{lr}_{\\text{max}} \\): Maximum learning rate (reached halfway through training).\n",
    "   - \\( \\text{lr}_{\\text{min}} \\): Minimum learning rate (start and end of the cycle).\n",
    "   - \\( t \\): Current time step.\n",
    "   - \\( T \\): Total training time.\n",
    "\n",
    "2. **Momentum Schedule:**\n",
    "   Momentum follows an inverse pattern of the learning rate. When the learning rate is high, momentum is low, and vice versa:\n",
    "   $$\n",
    "   \\text{mom}(t) =\n",
    "   \\begin{cases}\n",
    "   \\text{mom}_{\\text{min}} + (\\text{mom}_{\\text{max}} - \\text{mom}_{\\text{min}}) \\cdot \\frac{t}{T/2} & \\text{if } t \\leq T/2 \\\\\n",
    "   \\text{mom}_{\\text{max}} - (\\text{mom}_{\\text{max}} - \\text{mom}_{\\text{min}}) \\cdot \\frac{t - T/2}{T/2} & \\text{if } t > T/2\n",
    "   \\end{cases}\n",
    "   $$\n",
    "   - \\( \\text{mom}_{\\text{max}} \\): Maximum momentum.\n",
    "   - \\( \\text{mom}_{\\text{min}} \\): Minimum momentum.\n",
    "\n",
    "3. **Super-convergence:**\n",
    "   The key insight behind 1Cycle is the concept of super-convergence. By increasing the learning rate aggressively and then decreasing it, the model is pushed to learn faster and converge more effectively. The initial increase helps the model escape poor local minima, and the decrease ensures fine-tuning at the end of training.\n",
    "\n",
    "4. **Key Insights:**\n",
    "   - **Fast Learning:** The initial learning rate increase encourages the model to explore the parameter space more broadly.\n",
    "   - **Effective Fine-tuning:** The final learning rate decrease allows the model to settle into a good minimum.\n",
    "   - **Improved Generalization:** This cyclical pattern helps improve the generalization of the model, often leading to better performance on unseen data.\n",
    "\n",
    "### Advantages:\n",
    "- **Faster Training:** Helps models converge faster without compromising accuracy.\n",
    "- **Less Hyperparameter Tuning:** Reduces the need for manually adjusting the learning rate, as it adapts throughout the cycle.\n",
    "- **Better Generalization:** Leads to more robust models that generalize well to new data.\n",
    "\n",
    "1Cycle is particularly useful for large-scale deep learning tasks where achieving faster convergence is important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _beta1(cb): return cb.pg['betas'][0]\n",
    "rec = RecorderCB(lr=_lr, mom=_beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "lr,epochs = 6e-2,5\n",
    "model = get_model(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), rec]\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
