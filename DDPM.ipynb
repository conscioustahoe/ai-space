{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import logging\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter, itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import fastcore.all as fc\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor, nn, optim\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *\n",
    "from miniai.sgd import *\n",
    "from miniai.resnet import *\n",
    "from miniai.augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl, yl = 'image', 'label'\n",
    "dsd = load_dataset('fashion_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    b[xl] = [F.pad(TF.to_tensor(o), (2,2,2,2)) for o in b[xl]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dls.train\n",
    "xb, yb = next(iter(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(xb[:16], imsize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betamin, betamax, n_steps = 0.0001,0.02,1000\n",
    "beta = torch.linspace(betamin, betamax, n_steps)\n",
    "alpha = 1. - beta\n",
    "alphabar = alpha.cumprod(dim=0)\n",
    "sigma = beta.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphabar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(x0, ᾱ):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.randint(0, n_steps, (n, ), dtype=torch.long)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = ᾱ_t.sqrt() * x0 + (1 - ᾱ_t).sqrt() * ε\n",
    "    return (xt, t.to(device)), ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xt, t), ε = noisify(xb[:25], alphabar)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = fc.map_ex(t, '{}')\n",
    "show_images(xt, imsize=1.5, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, sz, alpha, alphabar, sigma, n_steps):\n",
    "    device = next(model.parameters()).device\n",
    "    x_t = torch.randn(sz, device=device)\n",
    "    preds = []\n",
    "\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(device)\n",
    "        ᾱ_t1 = alphabar[t-1] if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1 - alphabar[t]\n",
    "        b̄_t1 = 1 - ᾱ_t1\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * learn.model((x_t, t_batch))) / alphabar[t].sqrt()).clamp(-1, 1)\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt() * (1 - alpha[t]) / b̄_t + x_t * alpha[t].sqrt() * b̄_t1 / b̄_t + sigma[t] * z\n",
    "        preds.append(x_t.cpu())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMCB(Callback):\n",
    "    order = DeviceCB.order + 1\n",
    "\n",
    "    def __init__(self, n_steps, beta_min, beta_max):\n",
    "        super().__init__()\n",
    "        fc.store_attr()\n",
    "        self.beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n",
    "        self.α = 1. - self.beta \n",
    "        self.ᾱ = torch.cumprod(self.α, dim=0)\n",
    "        self.σ = self.beta.sqrt()\n",
    "    \n",
    "    def before_batch(self, learn):\n",
    "        learn.batch = noisify(learn.batch[0], self.ᾱ)\n",
    "    \n",
    "    def sample(self, model, sz):\n",
    "        return sample(model, sz, self.α, self.ᾱ, self.σ, self.n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(UNet2DModel):\n",
    "    def forward(self, x):\n",
    "        return super().forward(*x).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_cb = DDPMCB(n_steps=1000, beta_min=0.0001, beta_max=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 64), norm_num_groups=8)\n",
    "\n",
    "learn = TrainLearner(model, dls, nn.MSELoss())\n",
    "learn.fit(train=False, cbs=[ddpm_cb, SingleBatchCB()])\n",
    "\n",
    "(xt, t), ε = learn.batch\n",
    "\n",
    "show_images(xt[:25], titles=fc.map_ex(t[:25], '{}'), imsize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "epochs = 5\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [ddpm_cb, DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddpm(model):\n",
    "    for o in model.down_blocks:\n",
    "        for p in o.resnets:\n",
    "            p.conv2.weight.data.zero_()\n",
    "            for p in fc.L(o.downsamplers):\n",
    "                init.orthogonal_(p.conv.weight)\n",
    "\n",
    "    for o in model.up_blocks:\n",
    "        for p in o.resnets: p.conv2.weight.data.zero_()\n",
    "\n",
    "    model.conv_out.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ddpm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(optim.Adam, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TrainLearner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ddpm_cb.sample(learn.model, (16, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(samples[-1], figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(DataLoader(tds['train'], batch_size=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ddpm(b):\n",
    "    return noisify(default_collate(b)[xl], alphabar)\n",
    "\n",
    "def dl_ddpm(ds):\n",
    "    return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedPrecision(TrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def before_batch(self, learn):\n",
    "        self.autocast = torch.autocast(\"cuda\", dtype=torch.float16)\n",
    "        self.autocast.__enter__()\n",
    "\n",
    "    def after_loss(self, learn):\n",
    "        self.autocast.__exit__(None, None, None)\n",
    "        \n",
    "    def backward(self, learn):\n",
    "        self.scaler.scale(learn.loss).backward()\n",
    "\n",
    "    def step(self, learn):\n",
    "        self.scaler.step(learn.opt)\n",
    "        self.scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  1e-2\n",
    "epochs = 8\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [DeviceCB(), MixedPrecision(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]\n",
    "model = Unet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\n",
    "init_ddpm(model)\n",
    "learner = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(learn.model, (32, 1, 32, 32), alpha, alphabar, sigma, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(samples[-1][:25], imsize=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install accelerate` before running this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccelerateCB(TrainCB):\n",
    "\n",
    "    order = DeviceCB.order+10\n",
    "\n",
    "    def __init__(self, n_inp=1, mixed_precision=\"fp16\"):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.acc = Accelerator(mixed_precision=mixed_precision)\n",
    "        \n",
    "    def before_fit(self, learner):\n",
    "        learner.model, learner.opt, learner.dls.train, learner.dls.valid = self.acc.prepare(\n",
    "            learner.model, learner.opt, learner.dls.train, learner.dls.valid)\n",
    "\n",
    "    def backward(self, learn): \n",
    "        self.acc.backward(learner.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(x0, ᾱ):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n",
    "    return xt, t.to(device), ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMCB2(Callback):\n",
    "    def after_predict(self, learner): \n",
    "        learner.preds = learner.preds.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2DModel(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\n",
    "init_ddpm(model)\n",
    "cbs = [DDPMCB2(), DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched), AccelerateCB(n_inp=2)]\n",
    "learner = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sneaky trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultDL:\n",
    "    def __init__(self, dl, mult=2):\n",
    "        self.dl,self.mult = dl,mult\n",
    "    def __len__(self):\n",
    "        return len(self.dl)*self.mult\n",
    "    def __iter__(self):\n",
    "        for o in self.dl:\n",
    "            for i in range(self.mult):\n",
    "                yield o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
