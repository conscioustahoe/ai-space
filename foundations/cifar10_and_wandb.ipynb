{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Mapping\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import pickle, gzip, math, os, time, shutil, random, logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *\n",
    "from miniai.sgd import *\n",
    "from miniai.resnet import *\n",
    "from miniai.augment import *\n",
    "from miniai.accel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ff286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf98c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'img','label'\n",
    "name = \"cifar10\"\n",
    "dsd = load_dataset(name)\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[xl] = [TF.to_tensor(o)-0.5 for o in b[xl]]\n",
    "\n",
    "bs = 32\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dls.train\n",
    "xb,yb = next(iter(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f85dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(xb[:25]+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84015986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "def linear_sched(betamin=0.0001,betamax=0.02,n_steps=1000):\n",
    "    beta = torch.linspace(betamin, betamax, n_steps)\n",
    "    return SimpleNamespace(a=1.-beta, abar=(1.-beta).cumprod(dim=0), sig=beta.sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1000\n",
    "lin_abar = linear_sched(betamax=0.01)\n",
    "alphabar = lin_abar.abar\n",
    "alpha = lin_abar.a\n",
    "sigma = lin_abar.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f755a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(x0, ᾱ):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n",
    "    return (xt, t.to(device)), ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e13a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xt,t),ε = noisify(xb[:25],alphabar)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = fc.map_ex(t[:25], '{}')\n",
    "show_images(xt[:25].clip(-0.5, 0.5) + 0.5, imsize=1.5, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483dc958",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(UNet2DModel):\n",
    "    def forward(self, x): return super().forward(*x).sample\n",
    "    \n",
    "def init_ddpm(model):\n",
    "    for o in model.down_blocks:\n",
    "        for p in o.resnets:\n",
    "            p.conv2.weight.data.zero_()\n",
    "            for p in fc.L(o.downsamplers): init.orthogonal_(p.conv.weight)\n",
    "\n",
    "    for o in model.up_blocks:\n",
    "        for p in o.resnets: p.conv2.weight.data.zero_()\n",
    "\n",
    "    model.conv_out.weight.data.zero_()\n",
    "    \n",
    "def collate_ddpm(b): return noisify(default_collate(b)[xl], alphabar)\n",
    "def dl_ddpm(ds, nw=4): return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96356fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we've been using for FashionMNIST\n",
    "model = UNet(in_channels=3, out_channels=3, block_out_channels=(32, 64, 128, 256), norm_num_groups=8)\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default is a much larger model:\n",
    "model = UNet(in_channels=3, out_channels=3)\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdd254",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mem() # Free up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 1\n",
    "opt_func = partial(optim.AdamW, eps=1e-5)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [DeviceCB(), MixedPrecision(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]\n",
    "model = UNet(in_channels=3, out_channels=3)\n",
    "init_ddpm(model)\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8da91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9392db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, sz):\n",
    "    ps = next(model.parameters())\n",
    "    x_t = torch.randn(sz).to(ps)\n",
    "    preds = []\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=ps.device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(ps)\n",
    "        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1-alphabar[t]\n",
    "        b̄_t1 = 1-ᾱ_t1\n",
    "        noise = model((x_t, t_batch))\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * noise)/alphabar[t].sqrt())\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n",
    "        preds.append(x_t.float().cpu())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samples = sample(model, (bs, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (samples[-1] + 0.5).clamp(0,1)\n",
    "show_images(s[:16], imsize=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdad75",
   "metadata": {},
   "source": [
    "# W&B CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449daed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "class WandBCB(MetricsCB):\n",
    "    order=100\n",
    "    def __init__(self, config, *ms, project='ddpm_cifar10', **metrics):\n",
    "        fc.store_attr()\n",
    "        super().__init__(*ms, **metrics)\n",
    "        \n",
    "    def before_fit(self, learn): wandb.init(project=self.project, config=self.config)\n",
    "    def after_fit(self, learn): wandb.finish()\n",
    "\n",
    "    def _log(self, d): \n",
    "        if self.train: \n",
    "            wandb.log({'train_'+m:float(d[m]) for m in self.all_metrics})\n",
    "        else: \n",
    "            wandb.log({'val_'+m:float(d[m]) for m in self.all_metrics})\n",
    "            wandb.log({'samples':self.sample_figure(learn)})\n",
    "        print(d)\n",
    "\n",
    "        \n",
    "    def sample_figure(self, learn):\n",
    "        with torch.no_grad():\n",
    "            samples = sample(learn.model, (16, 3, 32, 32))\n",
    "        s = (samples[-1] + 0.5).clamp(0,1)\n",
    "        plt.clf()\n",
    "        fig, axs = get_grid(16)\n",
    "        for im,ax in zip(s[:16], axs.flat): show_image(im, ax=ax)\n",
    "        return fig\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        super().after_batch(learn) \n",
    "        wandb.log({'loss':learn.loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 10\n",
    "opt_func = partial(optim.AdamW, eps=1e-5)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "wandbcb =  WandBCB(config={'lr':lr, 'epochs':epochs, 'comments':'default unet logging test'})\n",
    "cbs = [DeviceCB(), MixedPrecision(), ProgressCB(plot=True), wandbcb, BatchSchedCB(sched)]\n",
    "model = model = UNet(in_channels=3, out_channels=3)\n",
    "init_ddpm(model)\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
