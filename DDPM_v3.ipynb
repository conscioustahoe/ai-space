{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3d1652",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models with miniai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28724450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ebda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from collections.abc import Mapping\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import fastcore.all as fc\n",
    "from fastcore.foundation import L\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn, optim, tensor\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "\n",
    "from miniai.accel import *\n",
    "from miniai.activations import *\n",
    "from miniai.augment import *\n",
    "from miniai.conv import *\n",
    "from miniai.datasets import *\n",
    "from miniai.init import *\n",
    "from miniai.learner import *\n",
    "from miniai.resnet import *\n",
    "from miniai.sgd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2d883-6db2-4a1f-b699-ff8343df0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "if fc.defaults.cpus>8: fc.defaults.cpus=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99edd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)\n",
    "\n",
    "@inplace\n",
    "def transformi(b): \n",
    "    b[xl] = [F.pad(TF.to_tensor(o), (2,2,2,2))-0.5 for o in b[xl]]\n",
    "\n",
    "bs = 512\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_sched(betamin=0.0001,betamax=0.02,n_steps=1000):\n",
    "    beta = torch.linspace(betamin, betamax, n_steps)\n",
    "    return SimpleNamespace(a=1.-beta, abar=(1.-beta).cumprod(dim=0), sig=beta.sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abar(t, T): return (t/T*math.pi/2).cos()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43476bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sched(n_steps=1000):\n",
    "    ts = torch.linspace(0, n_steps-1, n_steps)\n",
    "    ab = abar(ts,n_steps)\n",
    "    alp = ab/abar(ts-1,n_steps)\n",
    "    return SimpleNamespace(a=alp, abar=ab, sig=(1-alp).sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_abar = linear_sched().abar\n",
    "cos_abar = cos_sched().abar\n",
    "plt.plot(lin_abar, label='lin')\n",
    "plt.plot(cos_abar, label='cos')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lin_abar[1:]-lin_abar[:-1], label='lin')\n",
    "plt.plot(cos_abar[1:]-cos_abar[:-1], label='cos')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbb01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_abar = linear_sched(betamax=0.01).abar\n",
    "plt.plot(lin_abar, label='lin')\n",
    "plt.plot(cos_abar, label='cos')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5305ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lin_abar[1:]-lin_abar[:-1], label='lin')\n",
    "plt.plot(cos_abar[1:]-cos_abar[:-1], label='cos')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1000\n",
    "lin_abar = linear_sched(betamax=0.01)\n",
    "alphabar = lin_abar.abar\n",
    "alpha = lin_abar.a\n",
    "sigma = lin_abar.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(x0, ᾱ):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n",
    "    return (xt, t.to(device)), ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d37128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dls.train\n",
    "xb,yb = next(iter(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xt,t),ε = noisify(xb[:25],alphabar)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ac781",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = fc.map_ex(t[:25], '{}')\n",
    "show_images(xt[:25], imsize=1.5, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f26317",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(UNet2DModel):\n",
    "    def forward(self, x): return super().forward(*x).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddpm(model):\n",
    "    for o in model.down_blocks:\n",
    "        for p in o.resnets:\n",
    "            p.conv2.weight.data.zero_()\n",
    "            for p in fc.L(o.downsamplers): init.orthogonal_(p.conv.weight)\n",
    "\n",
    "    for o in model.up_blocks:\n",
    "        for p in o.resnets: p.conv2.weight.data.zero_()\n",
    "\n",
    "    model.conv_out.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b50882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ddpm(b): return noisify(default_collate(b)[xl], alphabar)\n",
    "def dl_ddpm(ds, nw=4): return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71991a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 25\n",
    "opt_func = partial(optim.AdamW, eps=1e-5)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [DeviceCB(), MixedPrecision(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]\n",
    "model = UNet(in_channels=1, out_channels=1, block_out_channels=(32, 64, 128, 256), norm_num_groups=8)\n",
    "init_ddpm(model)\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_path = Path('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73861f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(mdl_path/'fashion_ddpm3_25.pkl').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ff290",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, sz):\n",
    "    ps = next(model.parameters())\n",
    "    x_t = torch.randn(sz).to(ps)\n",
    "    preds = []\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=ps.device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(ps)\n",
    "        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1-alphabar[t]\n",
    "        b̄_t1 = 1-ᾱ_t1\n",
    "        noise = model((x_t, t_batch))\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * noise)/alphabar[t].sqrt())\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n",
    "        preds.append(x_t.float().cpu())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74371d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samples = sample(model, (n_samples, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (samples[-1]*2)#.clamp(-1,1)\n",
    "s.min(),s.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(s[:16], imsize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3842ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi2(b): b[xl] = [F.pad(TF.to_tensor(o), (2,2,2,2))*2-1 for o in b[xl]]\n",
    "\n",
    "tds2 = dsd.with_transform(transformi2)\n",
    "dls2 = DataLoaders.from_dd(tds2, bs, num_workers=fc.defaults.cpus)\n",
    "\n",
    "cmodel = torch.load('models/data_aug2.pkl')\n",
    "del(cmodel[8])\n",
    "del(cmodel[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.fid import ImageEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = ImageEval(cmodel, dls2, cbs=[DeviceCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.fid(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abe6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.min(),s.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.fid(xb*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc676e",
   "metadata": {},
   "source": [
    "### Skip sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_skip(model, sz):\n",
    "    ps = next(model.parameters())\n",
    "    x_t = torch.randn(sz).to(ps)\n",
    "    preds = []\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=ps.device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(ps)\n",
    "        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1-alphabar[t]\n",
    "        b̄_t1 = 1-ᾱ_t1\n",
    "        if t%3==0 or t<50: noise = model((x_t, t_batch))\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * noise)/alphabar[t].sqrt())\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n",
    "        preds.append(x_t.cpu().float())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31734cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samples = sample_skip(model, (n_samples, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e098527",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (samples[-1]*2)#.clamp(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5471a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(s[:25], imsize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb782f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.fid(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample2(model, sz):\n",
    "    ps = next(model.parameters())\n",
    "    x_t = torch.randn(sz).to(ps)\n",
    "    sample_at = {t for t in range(n_steps) if (t+101)%((t+101)//100)==0}\n",
    "    preds = []\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=ps.device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(ps)\n",
    "        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1-alphabar[t]\n",
    "        b̄_t1 = 1-ᾱ_t1\n",
    "        if t in sample_at: noise = model((x_t, t_batch))\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * noise)/alphabar[t].sqrt())\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n",
    "        if t in sample_at: preds.append(x_t.float().cpu())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samples = sample2(model, (n_samples, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (samples[-1]*2)#.clamp(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8281c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(s[:25], imsize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccecafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.fid(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
