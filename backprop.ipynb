{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## The forward and backward passes"
      ],
      "metadata": {
        "id": "L1ikA-MQJ9dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle, gzip, math, os, time, shutil, torch, matplotlib as mpl, numpy as np\n",
        "from pathlib import Path\n",
        "from torch import tensor\n",
        "from fastcore.test import test_close\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
        "np.set_printoptions(precision=2, linewidth=125)\n",
        "\n",
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True)\n",
        "path_gz = path_data/'mnist.pkl.gz'\n",
        "\n",
        "if not path_gz.exists():\n",
        "  urlretrieve(MNIST_URL, path_gz)\n",
        "\n",
        "with gzip.open(path_gz, 'rb') as f:\n",
        "   ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ],
      "metadata": {
        "id": "4V3n1VYRKCe_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Foundations version"
      ],
      "metadata": {
        "id": "99ULq4JTK3kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic architecture"
      ],
      "metadata": {
        "id": "SsEGiFH8K6ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, m = x_train.shape\n",
        "c = y_train.max() + 1\n",
        "n, m, c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNFPhtgpK1ol",
        "outputId": "e4e795cb-6831-49f4-da31-894eef6d26b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nh = 50"
      ],
      "metadata": {
        "id": "p4rj6WkeM97F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.randn(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh, 1)\n",
        "b2 = torch.zeros(1)"
      ],
      "metadata": {
        "id": "X-sn9HUfMzAI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lin(x, w, b):\n",
        "  return x @ w + b"
      ],
      "metadata": {
        "id": "N4c1e_uLNEAR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return x.clamp_min(0.)"
      ],
      "metadata": {
        "id": "SLrT7tdOVj9e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = lin(x_valid, w1, b1)\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOsTqmejVozl",
        "outputId": "e582d629-6b01-48b4-a70f-78dfd4314a9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = relu(t)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5BrpVoWVsuW",
        "outputId": "bb2b9fce-e5e3-4fde-d5c7-ce42a879161b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.00, 11.87,  0.00,  ...,  5.48,  2.14, 15.30],\n",
              "        [ 5.38, 10.21,  0.00,  ...,  0.88,  0.08, 20.23],\n",
              "        [ 3.31,  0.12,  3.10,  ..., 16.89,  0.00, 24.74],\n",
              "        ...,\n",
              "        [ 4.01, 10.35,  0.00,  ...,  0.23,  0.00, 18.28],\n",
              "        [10.62,  0.00, 10.72,  ...,  0.00,  0.00, 18.23],\n",
              "        [ 2.84,  0.00,  1.43,  ...,  0.00,  5.75,  2.12]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(xb):\n",
        "  l1 = lin(xb, w1, b1)\n",
        "  l2 = relu(l1)\n",
        "  return lin(l1, w2, b2)"
      ],
      "metadata": {
        "id": "jZeyMEQPV4qb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model(x_valid)\n",
        "res.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGAnzToMWEM0",
        "outputId": "f2cdacff-2129-47e6-c622-a38d048db2d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function: MSE"
      ],
      "metadata": {
        "id": "88UhwbPAWUb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"
      ],
      "metadata": {
        "id": "hGAbxpy3WW9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.shape, y_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjYwvMvEWQes",
        "outputId": "c426b098-f67e-4fad-eb59-ffc70517d839"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10000, 1]), torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(res - y_valid).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFwA9N6-WdGQ",
        "outputId": "f6493015-f65a-4665-89bb-ca561d276cf4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(res.squeeze() - y_valid).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO6doeRfWqjb",
        "outputId": "bbb30c08-b4e1-430e-ac10-afe12a4065ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(res[:,0] - y_valid).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_dv60IWvC8",
        "outputId": "4b2f6ebf-08d5-494a-b6b4-263852ddabd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, y_valid = y_train.float(), y_valid.float()\n",
        "preds = model(x_train)\n",
        "preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulLQHG9yW0iu",
        "outputId": "7fca5358-34de-4825-e3c5-cedbc05d1698"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(output, target):\n",
        "  return (output[:,0] - target).pow(2).mean()"
      ],
      "metadata": {
        "id": "9lmvQLl2jxx_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(preds, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D13w5gquj_dy",
        "outputId": "de0dc502-c723-4e42-9f05-ab477741918f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6895.60)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradients and backward pass"
      ],
      "metadata": {
        "id": "bTGncKQ-kO2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import symbols, diff\n",
        "x, y = symbols('x y')\n",
        "diff(x**2, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "Suws_5T1kFYZ",
        "outputId": "404c60de-1b6f-4015-91d9-51f67b73f546"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2*x"
            ],
            "text/latex": "$\\displaystyle 2 x$"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff(3*x**2+9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "zycAvWvekcS2",
        "outputId": "c7094598-57dc-4230-c3e9-1efc44073d3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6*x"
            ],
            "text/latex": "$\\displaystyle 6 x$"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    # grad of matmul with respect to input\n",
        "    inp.g = out.g @ w.t()\n",
        "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "    b.g = out.g.sum(0)"
      ],
      "metadata": {
        "id": "gwlaUaidkiie"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = lin(inp, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    out = lin(l2, w2, b2)\n",
        "    diff = out[:,0]-targ\n",
        "    loss = diff.pow(2).mean()\n",
        "\n",
        "    # backward pass:\n",
        "    out.g = 2.*diff[:,None] / inp.shape[0]\n",
        "    lin_grad(l2, out, w2, b2)\n",
        "    l1.g = (l1>0).float() * l2.g\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "metadata": {
        "id": "FkbAIQH-0KGm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "metadata": {
        "id": "-qT6G_G30M85"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save for testing against later\n",
        "def get_grad(x):\n",
        "  return x.g.clone()\n",
        "\n",
        "chks = w1,w2,b1,b2,x_train\n",
        "grads = w1g,w2g,b1g,b2g,ig = tuple(map(get_grad, chks))"
      ],
      "metadata": {
        "id": "dssJZOSP2APk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We* cheat a little bit and use PyTorch autograd to check our results."
      ],
      "metadata": {
        "id": "1FpeqEZO2ShX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mkgrad(x):\n",
        "  return x.clone().requires_grad_(True)\n",
        "\n",
        "ptgrads = w12,w22,b12,b22,xt2 = tuple(map(mkgrad, chks))"
      ],
      "metadata": {
        "id": "kBXyXWAG2S4S"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(inp, targ):\n",
        "    l1 = lin(inp, w12, b12)\n",
        "    l2 = relu(l1)\n",
        "    out = lin(l2, w22, b22)\n",
        "    return mse(out, targ)"
      ],
      "metadata": {
        "id": "02JJKhgL2uDF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = forward(xt2, y_train)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "eSJT4MUh3KAJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in zip(grads, ptgrads):\n",
        "  test_close(a, b.grad, eps=0.01)"
      ],
      "metadata": {
        "id": "1cbVNE6S4eaP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refactor model"
      ],
      "metadata": {
        "id": "IJxH2qSV9mxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers as classes"
      ],
      "metadata": {
        "id": "kiK02B1G9pxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "      self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "metadata": {
        "id": "dcWZ05Zf4q1b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = lin(inp, self.w, self.b)\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = self.inp.t() @ self.out.g\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "metadata": {
        "id": "TCGNOzi3-U66"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp,self.targ = inp,targ\n",
        "        self.out = mse(inp, targ)\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "metadata": {
        "id": "D5RebiL2AFd4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "\n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "\n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers):\n",
        "            l.backward()"
      ],
      "metadata": {
        "id": "_WOstSFtA9Gj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(w1, b1, w2, b2)"
      ],
      "metadata": {
        "id": "gt9Czw4zB6hA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model(x_train, y_train)"
      ],
      "metadata": {
        "id": "Hbk_pRuaB8zv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.backward()"
      ],
      "metadata": {
        "id": "JsoaOzFhCFQG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(w2g, w2.g, eps=0.01)\n",
        "test_close(b2g, b2.g, eps=0.01)\n",
        "test_close(w1g, w1.g, eps=0.01)\n",
        "test_close(b1g, b1.g, eps=0.01)\n",
        "test_close(ig, x_train.g, eps=0.01)"
      ],
      "metadata": {
        "id": "N-IPrk0pCwQx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module.forward()"
      ],
      "metadata": {
        "id": "kqEOGxrdDB6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "\n",
        "    def forward(self): raise Exception('not implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)\n",
        "    def bwd(self): raise Exception('not implemented')"
      ],
      "metadata": {
        "id": "_RT1-ptQC-pk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.)\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "metadata": {
        "id": "mjzm_-n-K_66"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ self.out.g\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "metadata": {
        "id": "B7Mx1VuiLBz_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "metadata": {
        "id": "xsacd8jALGKf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(w1, b1, w2, b2)"
      ],
      "metadata": {
        "id": "JqR5Yt0CLN2a"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model(x_train, y_train)"
      ],
      "metadata": {
        "id": "VRzfS0ZoLP5V"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.backward()"
      ],
      "metadata": {
        "id": "cN5ZgQgvLRRA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(w2g, w2.g, eps=0.01)\n",
        "test_close(b2g, b2.g, eps=0.01)\n",
        "test_close(w1g, w1.g, eps=0.01)\n",
        "test_close(b1g, b1.g, eps=0.01)\n",
        "test_close(ig, x_train.g, eps=0.01)"
      ],
      "metadata": {
        "id": "ZMqAj80wLSne"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd"
      ],
      "metadata": {
        "id": "mYIbiuQ6LWTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "eigGtQC6LT00"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super().__init__()\n",
        "        self.w = torch.randn(n_in,n_out).requires_grad_()\n",
        "        self.b = torch.zeros(n_out).requires_grad_()\n",
        "    def forward(self, inp):\n",
        "        return inp@self.w + self.b"
      ],
      "metadata": {
        "id": "-gmhUxYPLX4i"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [Linear(n_in,nh), nn.ReLU(), Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return F.mse_loss(x, targ[:,None])"
      ],
      "metadata": {
        "id": "4qA8jDMdLfuU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(m, nh, 1)\n",
        "loss = model(x_train, y_train)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "8Fvfukr-Lk5I"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l0 = model.layers[0]\n",
        "l0.b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpXmk-RTLmfV",
        "outputId": "323d6f10-ddfe-4a6a-d493-06909b5f6104"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-19.60,  -2.40,  -0.12,   1.99,  12.78, -15.32, -18.45,   0.35,   3.75,  14.67,  10.81,  12.20,  -2.95, -28.33,\n",
              "          0.76,  69.15, -21.86,  49.78,  -7.08,   1.45,  25.20,  11.27, -18.15, -13.13, -17.69, -10.42,  -0.13, -18.89,\n",
              "        -34.81,  -0.84,  40.89,   4.45,  62.35,  31.70,  55.15,  45.13,   3.25,  12.75,  12.45,  -1.41,   4.55,  -6.02,\n",
              "        -62.51,  -1.89,  -1.41,   7.00,   0.49,  18.72,  -4.84,  -6.52])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6ghQxlVLn8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}